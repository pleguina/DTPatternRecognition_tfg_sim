{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df76a079",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ROOT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Pelayo Leguina - 2024\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Este script permite convertir un archivo ROOT con clases tipo TClonesArray a un DataFrame de pandas.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Mira el archivo environment.yml para ver cómo hacerlo. Una vez tengas el env creado, activa el env y ejecuta este notebook. \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Puedes seguir trabajando aqui o exportar el dataframe a un archivo csv para trabajar en otro lado.\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mROOT\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ROOT'"
     ]
    }
   ],
   "source": [
    "#Pelayo Leguina - 2024\n",
    "\n",
    "#Este script permite convertir un archivo ROOT con clases tipo TClonesArray a un DataFrame de pandas.\n",
    "\n",
    "# Para correr este script es necesario tener instalado ROOT y pandas\n",
    "# Para tener root instalado, hay que generar el env con conda. \n",
    "# Mira el archivo environment.yml para ver cómo hacerlo. Una vez tengas el env creado, activa el env y ejecuta este notebook. \n",
    "# Puedes seguir trabajando aqui o exportar el dataframe a un archivo csv para trabajar en otro lado.\n",
    "\n",
    "\n",
    "import ROOT\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir la ruta del archivo ROOT y el nombre del árbol\n",
    "ruta_archivo_root = 'DTDPGNtuple_12_4_2_Phase2Concentrator_Simulation_89.root'\n",
    "nombre_arbol = 'dtNtupleProducer/DTTREE'\n",
    "\n",
    "# Abrir el archivo ROOT\n",
    "archivo = ROOT.TFile.Open(ruta_archivo_root)\n",
    "if not archivo or archivo.IsZombie():\n",
    "    raise FileNotFoundError(f\"No se pudo abrir el archivo ROOT en {ruta_archivo_root}\")\n",
    "\n",
    "# Obtener el árbol\n",
    "arbol = archivo.Get(nombre_arbol)\n",
    "if not arbol:\n",
    "    raise ValueError(f\"No se encontró el árbol '{nombre_arbol}' en el archivo ROOT.\")\n",
    "\n",
    "# Listas de ramas\n",
    "ramas_event = ['event_eventNumber']\n",
    "ramas_digis_numericas = [\"digi_nDigis\", \"digi_wheel\", \"digi_sector\", \"digi_station\", \n",
    "    \"digi_superLayer\", \"digi_layer\", \"digi_wire\", \"digi_time\"]\n",
    "ramas_seg_numericas = [\n",
    "    \"seg_nSegments\", \"seg_wheel\", \"seg_sector\", \"seg_station\", \"seg_hasPhi\", \n",
    "    \"seg_hasZed\", \"seg_posLoc_x\", \"seg_posLoc_y\", \"seg_posLoc_z\", \n",
    "    \"seg_dirLoc_x\", \"seg_dirLoc_y\", \"seg_dirLoc_z\", \"seg_posLoc_x_SL1\", \n",
    "    \"seg_posLoc_x_SL3\", \"seg_posLoc_x_midPlane\", \"seg_posGlb_phi\", \n",
    "    \"seg_posGlb_eta\", \"seg_dirGlb_phi\", \"seg_dirGlb_eta\", \"seg_phi_t0\", \n",
    "    \"seg_phi_vDrift\", \"seg_phi_normChi2\", \"seg_phi_nHits\", \n",
    "    \"seg_z_normChi2\", \"seg_z_nHits\"\n",
    "]\n",
    "ramas_seg_arrays = [\n",
    "    'seg_phiHits_pos', 'seg_phiHits_posCh', 'seg_phiHits_posErr', \n",
    "    'seg_phiHits_side', 'seg_phiHits_wire', 'seg_phiHits_wirePos', \n",
    "    'seg_phiHits_layer', 'seg_phiHits_superLayer', 'seg_phiHits_time', \n",
    "    'seg_phiHits_timeCali'\n",
    "]\n",
    "\n",
    "ramas_a_extraer = ramas_event + ramas_digis_numericas + ramas_seg_numericas + ramas_seg_arrays\n",
    "\n",
    "# Inicializar diccionario para almacenar los datos\n",
    "data = {rama: [] for rama in ramas_a_extraer}\n",
    "\n",
    "# Iterar sobre las entradas del árbol\n",
    "for evento in arbol:\n",
    "    for rama in ramas_a_extraer:\n",
    "        valor = getattr(evento, rama, None)\n",
    "        \n",
    "        if valor is None:\n",
    "            data[rama].append(None)\n",
    "            continue\n",
    "\n",
    "        # Verificar si es un TClonesArray\n",
    "        if hasattr(valor, 'GetEntriesFast'):\n",
    "            valores = []\n",
    "            for i in range(valor.GetEntriesFast()):\n",
    "                elemento = valor.At(i)\n",
    "                if hasattr(elemento, '__len__'):  # Si es vectorizable\n",
    "                    valores.append([x for x in elemento])\n",
    "                else:\n",
    "                    valores.append(elemento)\n",
    "            data[rama].append(valores)\n",
    "        elif isinstance(valor, ROOT.TVectorF) or isinstance(valor, ROOT.TVectorD):\n",
    "            # Manejar TVectorT como TVectorF (float) o TVectorD (double)\n",
    "            data[rama].append([valor[i] for i in range(valor.GetNrows())])\n",
    "        elif isinstance(valor, (int, float)):\n",
    "            # Escalar simple\n",
    "            data[rama].append(valor)\n",
    "        else:\n",
    "            try:\n",
    "                # Intentar convertir a lista si es iterable\n",
    "                data[rama].append(list(valor))\n",
    "            except TypeError:\n",
    "                data[rama].append(valor)\n",
    "\n",
    "# Cerrar el archivo ROOT\n",
    "archivo.Close()\n",
    "\n",
    "# Verificar que todas las ramas tienen la misma longitud\n",
    "longitudes = {rama: len(val) for rama, val in data.items()}\n",
    "print(\"Longitud de cada rama:\")\n",
    "for rama, longitud in longitudes.items():\n",
    "    print(f\"{rama}: {longitud}\")\n",
    "\n",
    "# Convertir a DataFrame\n",
    "try:\n",
    "    df = pd.DataFrame(data)\n",
    "except ValueError as e:\n",
    "    print(\"Error al crear el DataFrame:\", e)\n",
    "    for rama, longitud in longitudes.items():\n",
    "        print(f\"{rama}: {longitud}\")\n",
    "    raise\n",
    "\n",
    "# Mostrar una vista previa del DataFrame\n",
    "print(\"\\nVista previa del DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Contar los hits en las ramas tipo array\n",
    "for rama in ramas_seg_arrays:\n",
    "    if rama in df.columns:\n",
    "        df[f'{rama}_count'] = df[rama].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "# Mostrar conteos\n",
    "for rama in ramas_seg_arrays:\n",
    "    if f'{rama}_count' in df.columns:\n",
    "        print(f\"\\nNúmero de hits por evento en '{rama}':\")\n",
    "        print(df[f'{rama}_count'].head())\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df.to_csv('data.csv', index=False)\n",
    "print('Data saved in data.csv')\n",
    "\n",
    "#Ahora ya puedes trabajar con el df para generar las entradas/verdades de tu modelo de ML\n",
    "#Siempre asegurate de preprocesar el df, rellenar los NaNs, normalizar los datos, etc.\n",
    "\n",
    "#Recuerda que deberíamos filtrar los digis pertenecientes a la SL2 (no trabajamos en esa dimension)\n",
    "#Lo mismo para los segmentos que no tienen hits en phi (son segmentos de la SL2 y tambien tenemos que cargarnoslos)\n",
    "# Suerte! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c134a921",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnewGeo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtGeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chain\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\GitHub\\DTPatternRecognition_tfg_sim\\rootEnv\\newGeo\\dtGeometry.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#dtGeometry.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#This script contains the functions to parse the DT geometry XML file and create Chamber, SuperLayer, Layer, and Wire objects.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mET\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from newGeo.dtGeometry import *\n",
    "from itertools import chain\n",
    "import logging\n",
    "\n",
    "geometry_xml_path = \"newGeo/DTGeometry.xml\"\n",
    "\n",
    "\n",
    "# Parse DT Geometry XML\n",
    "print(\"\\nParsing DT Geometry XML...\")\n",
    "df_geometry = parse_dtgeometry_xml(geometry_xml_path)\n",
    "\n",
    "def create_wire_position_mapping(df_geometry):\n",
    "    mapping = {}\n",
    "    for idx, row in df_geometry.iterrows():\n",
    "        chamber_rawId = row['Chamber_rawId']\n",
    "        superLayerNumber = row['SuperLayerNumber']\n",
    "        layerNumber = row['LayerNumber']\n",
    "        channels_total = row['Channels_total']\n",
    "        wireFirst = row['WirePositions_FirstWire']\n",
    "        wireLast = row['WirePositions_LastWire']\n",
    "        # Create Wire object to get positions\n",
    "        wire_obj = Wire(wireFirst, wireLast, channels_total, row['Layer_Local_z'])\n",
    "        # Map wire numbers to positions\n",
    "        for wire_idx, x_pos in enumerate(wire_obj.positions):\n",
    "            wire_number = wire_idx + 1  # Assuming wire numbers start from 1\n",
    "            key = (chamber_rawId, superLayerNumber, layerNumber, wire_number)\n",
    "            mapping[key] = x_pos\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def explode_dataframe(df, list_columns):\n",
    "    \"\"\"Explota columnas con listas en filas separadas.\"\"\"\n",
    "    # Repetir índices según la longitud de las listas\n",
    "    lengths = df[list_columns[0]].apply(len)\n",
    "    idx = df.index.repeat(lengths)\n",
    "\n",
    "    # Explotar las columnas de listas\n",
    "    exploded_data = {col: list(chain.from_iterable(df[col])) for col in list_columns}\n",
    "\n",
    "    # Agregar las columnas que no son listas\n",
    "    exploded_df = pd.DataFrame(exploded_data, index=idx)\n",
    "    non_list_columns = df.columns.difference(list_columns)\n",
    "    for col in non_list_columns:\n",
    "        exploded_df[col] = df[col].repeat(lengths)\n",
    "\n",
    "    return exploded_df.reset_index(drop=True)\n",
    "\n",
    "def add_chamber_rawId_to_digis(df):\n",
    "    \"\"\"Agrega la columna chamber_rawId basada en wheel, station y sector.\"\"\"\n",
    "    chamber_rawIds = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            rawId = get_rawId(row['digi_wheel'], row['digi_station'], row['digi_sector'])\n",
    "        except ValueError as e:\n",
    "            logging.error(f\"Error al calcular rawId en el índice {idx}: {e}\")\n",
    "            rawId = None\n",
    "        chamber_rawIds.append(rawId)\n",
    "    df['digi_chamber_rawId'] = chamber_rawIds\n",
    "    return df\n",
    "\n",
    "def map_digi_wires_to_positions(df, wire_position_mapping):\n",
    "    \"\"\"Mapea los wires a sus posiciones en x usando wire_position_mapping.\"\"\"\n",
    "    x_positions = []\n",
    "    for idx, row in df.iterrows():\n",
    "        key = (row['digi_chamber_rawId'], row['digi_superLayer'], row['digi_layer'], row['digi_wire'])\n",
    "        x_pos = wire_position_mapping.get(key, None)  # Por defecto, None si no se encuentra la clave\n",
    "        x_positions.append(x_pos)\n",
    "    df['digi_x_pos'] = x_positions\n",
    "    return df\n",
    "\n",
    "def reconstruct_dataframe(df_original, df_flattened, list_columns, extra_columns):\n",
    "    \"\"\"\n",
    "    Reconstruye el DataFrame original, agrupando las columnas calculadas en listas.\n",
    "\n",
    "    Args:\n",
    "    - df_original: DataFrame original con listas.\n",
    "    - df_flattened: DataFrame aplanado después de las explosiones y cálculos.\n",
    "    - list_columns: Columnas que originalmente estaban en formato de lista.\n",
    "    - extra_columns: Nuevas columnas a agregar al DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame reconstruido con las columnas adicionales.\n",
    "    \"\"\"\n",
    "    # Crear índice auxiliar para asociar filas a las originales\n",
    "    df_flattened[\"original_index\"] = df_original.index.repeat(\n",
    "        df_original[list_columns[0]].apply(len)\n",
    "    )\n",
    "\n",
    "    # Agrupar filas aplanadas según el índice original\n",
    "    grouped = df_flattened.groupby(\"original_index\")\n",
    "\n",
    "    # Agregar de vuelta las columnas originales y las nuevas\n",
    "    for col in list_columns + extra_columns:\n",
    "        df_original[col] = grouped[col].apply(list).reindex(df_original.index).tolist()\n",
    "\n",
    "    return df_original\n",
    "\n",
    "\n",
    "\n",
    "wire_position_mapping = create_wire_position_mapping(df_geometry)\n",
    "\n",
    "# Columnas con valores en listas\n",
    "list_columns = ['digi_wheel', 'digi_sector', 'digi_station', 'digi_superLayer', 'digi_layer', 'digi_wire']\n",
    "\n",
    "# Explotar el DataFrame para trabajar con cada digi individualmente\n",
    "df_flattened = explode_dataframe(df, list_columns)\n",
    "\n",
    "# Agregar la columna chamber_rawId\n",
    "df_flattened = add_chamber_rawId_to_digis(df_flattened)\n",
    "\n",
    "# Calcular las posiciones de los wires\n",
    "df_flattened = map_digi_wires_to_positions(df_flattened, wire_position_mapping)\n",
    "\n",
    "# Reconstruir el DataFrame original con la nueva columna\n",
    "df = reconstruct_dataframe(df, df_flattened, list_columns, ['digi_x_pos'])\n",
    "\n",
    "# Reordenar columnas para que digi_x_pos aparezca después de digi_wire\n",
    "columns = df.columns.tolist()\n",
    "digi_wire_index = columns.index('digi_wire')\n",
    "columns.insert(digi_wire_index + 1, columns.pop(columns.index('digi_x_pos')))\n",
    "df = df[columns]\n",
    "\n",
    "# Mostrar el DataFrame final\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d37f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
